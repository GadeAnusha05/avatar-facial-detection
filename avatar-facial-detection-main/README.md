# avatar-facial-detection
# ğŸ˜Š Real-Time Facial Emotion Recognition with Voice Feedback

This project uses **MediaPipe**, **OpenCV**, and **pyttsx3** to detect facial expressions from a webcam feed and respond with real-time **emotion-based speech** and an animated avatar overlay.

---

## ğŸš€ Features

- ğŸ” Detects facial emotions: **Happy**, **Sad**, **Angry**, **Surprised**, **Fear**, **Disgust**, **Neutral**
- ğŸ™ï¸ Speaks out your emotion in real-time using text-to-speech (TTS)
- ğŸ§  Emotion classification based on facial landmarks (eyes, lips, mouth, iris, etc.)
- ğŸ¨ Avatar visualization beside your webcam using MediaPipe's face mesh
- ğŸ§µ Smooth, non-blocking voice output using threaded speech queue
- ğŸ” Fast reaction â€” emotion updates every few frames

---

## ğŸ–¥ï¸ Demo

| Webcam Feed | Avatar Canvas |
|-------------|----------------|
| ![webcam-feed](demo/webcam.gif) | ![avatar-canvas](demo/avatar.gif) |

---

## ğŸ› ï¸ Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/facial-emotion-voice-feedback.git
   cd facial-emotion-voice-feedback

2.Create a virtual environment (optional but recommended):

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
3.Install dependencies:

bash
Copy
Edit
pip install -r requirements.txt
4.ğŸ“¦ Dependencies
text
Copy
Edit
opencv-python
mediapipe
numpy
pyttsx3
5.Install manually if needed:

bash
Copy
Edit
pip install opencv-python mediapipe numpy pyttsx3
6.â–¶ï¸ Run the App
bash
Copy
Edit
python emotion_voice_app.py
Press ESC to exit the window.

7.ğŸ“ Project Structure
bash
Copy
Edit
.
â”œâ”€â”€ emotion_voice_app.py       # Main Python script
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ demo/
    â”œâ”€â”€ webcam.gif             # (Optional) Sample output GIFs
    â””â”€â”€ avatar.gif
